{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "covered-matter",
   "metadata": {},
   "source": [
    "# 5.2 CNN 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "patient-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "passing-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()   # cuda를 쓸 수 있는지 확인하는 코드\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")  # use_cude의 결과에 따라 데이터를 cuda 혹은 cpu로 보내도록 가리키는 역할\n",
    "EPOCHS = 40  \n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "married-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용, 테스트용 데이터셋 불러오기\n",
    "# 코드 간결하게 하기 위해 fashion MNIST데이터 셋을 DataLoader부를 때 정의\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('./data', train = True, download = True, transform = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize((0.1307, ), (0.3081,))])), batch_size = BATCH_SIZE , shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('./data', train = False, download = True, transform = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize((0.1307, ), (0.3081,))])), batch_size = BATCH_SIZE , shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stunning-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫 컨볼루션 계층에서는 10개의 특징 맵을 생성하고 두 번째 컨볼루션 계층에서는 10개의 특징 맵을 받아 20개의 특징 맵을 만듦\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size = 5)  # nn.Conv2d의 첫 두 파라미터는 입력 채널 수와 출력 채널 수, 여기서 사용하는 데이터셋은 흑백 이미지이기 때문에 색상 채널이 1개 뿐\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size = 5)  # 커널 사이즈는 숫자 하나만 지정하면 정사각형으로 간주. (3,5)하면 3*5크기의 직사각형 만들 수 있음\n",
    "        self.drop = nn.Dropout2d()  # 컨볼루션 결과로 나온 출력값에 드롭아웃. 드롭아웃 함수 사용 안하고 모듈 이용해 드롭아웃 인스턴스 생성\n",
    "        self.fc1 = nn.Linear(320,50) # 입력 크기 320, 출력 크기 50\n",
    "        self.fc2 = nn.Linear(50,10)  # 입력 크기 50, 출력 크기 10\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))  # max_pool2d함수의 두 번째 파라미터는 커널 크기\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))  # 드롭아웃과 같이 학습 파라미터가 없으므로 nn.MaxPool2d같이 일반 모듈 사용해도 됨\n",
    "        # 특징 맵 이후 출력을 하는 일반 인공 신경망은 1차원 입력을 받음\n",
    "        x = x.view(-1,320)  # 2차원 -> 1차원\n",
    "        # 앞서 추출한 특징들을 입력으로 받아 분류하는 (일반)신경망 계층 구성\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sunset-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(DEVICE)  # 만든 모델 인스턴스\n",
    "optimizer = optim. SGD(model.parameters(), lr = 0.01, momentum = 0.5) # 최적화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "atlantic-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0 :\n",
    "            print('train epoch : {}[{}/{} ({: .0f}%)]\\tloss:{:.6f}'.format(epoch, len(data), len(train_loader.dataset),\n",
    "                                                                           100* batch_idx / len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 1[64/60000 ( 0%)]\tloss:2.326163\n",
      "train epoch : 1[64/60000 ( 21%)]\tloss:1.275830\n",
      "train epoch : 1[64/60000 ( 43%)]\tloss:0.885789\n",
      "train epoch : 1[64/60000 ( 64%)]\tloss:0.945444\n",
      "train epoch : 1[64/60000 ( 85%)]\tloss:1.160420\n",
      "[1] test loss : 0.6550, accuracy: 74.83%\n",
      "train epoch : 2[64/60000 ( 0%)]\tloss:0.854438\n",
      "train epoch : 2[64/60000 ( 21%)]\tloss:0.804505\n",
      "train epoch : 2[64/60000 ( 43%)]\tloss:0.723741\n",
      "train epoch : 2[64/60000 ( 64%)]\tloss:0.916207\n",
      "train epoch : 2[64/60000 ( 85%)]\tloss:0.546390\n",
      "[2] test loss : 0.5630, accuracy: 77.67%\n",
      "train epoch : 3[64/60000 ( 0%)]\tloss:0.634286\n",
      "train epoch : 3[64/60000 ( 21%)]\tloss:0.760467\n",
      "train epoch : 3[64/60000 ( 43%)]\tloss:0.732816\n",
      "train epoch : 3[64/60000 ( 64%)]\tloss:0.505225\n",
      "train epoch : 3[64/60000 ( 85%)]\tloss:0.570690\n",
      "[3] test loss : 0.5155, accuracy: 80.28%\n",
      "train epoch : 4[64/60000 ( 0%)]\tloss:0.475301\n",
      "train epoch : 4[64/60000 ( 21%)]\tloss:0.747238\n",
      "train epoch : 4[64/60000 ( 43%)]\tloss:0.559839\n",
      "train epoch : 4[64/60000 ( 64%)]\tloss:0.651901\n",
      "train epoch : 4[64/60000 ( 85%)]\tloss:0.524791\n",
      "[4] test loss : 0.4703, accuracy: 81.49%\n",
      "train epoch : 5[64/60000 ( 0%)]\tloss:0.449324\n",
      "train epoch : 5[64/60000 ( 21%)]\tloss:0.799137\n",
      "train epoch : 5[64/60000 ( 43%)]\tloss:0.609853\n",
      "train epoch : 5[64/60000 ( 64%)]\tloss:0.548015\n",
      "train epoch : 5[64/60000 ( 85%)]\tloss:0.526520\n",
      "[5] test loss : 0.4463, accuracy: 83.33%\n",
      "train epoch : 6[64/60000 ( 0%)]\tloss:0.476254\n",
      "train epoch : 6[64/60000 ( 21%)]\tloss:0.511563\n",
      "train epoch : 6[64/60000 ( 43%)]\tloss:0.482598\n",
      "train epoch : 6[64/60000 ( 64%)]\tloss:0.318325\n",
      "train epoch : 6[64/60000 ( 85%)]\tloss:0.604499\n",
      "[6] test loss : 0.4154, accuracy: 84.67%\n",
      "train epoch : 7[64/60000 ( 0%)]\tloss:0.534202\n",
      "train epoch : 7[64/60000 ( 21%)]\tloss:0.266706\n",
      "train epoch : 7[64/60000 ( 43%)]\tloss:0.494316\n",
      "train epoch : 7[64/60000 ( 64%)]\tloss:0.305465\n",
      "train epoch : 7[64/60000 ( 85%)]\tloss:0.480968\n",
      "[7] test loss : 0.3939, accuracy: 85.78%\n",
      "train epoch : 8[64/60000 ( 0%)]\tloss:0.445722\n",
      "train epoch : 8[64/60000 ( 21%)]\tloss:0.503049\n",
      "train epoch : 8[64/60000 ( 43%)]\tloss:0.265801\n",
      "train epoch : 8[64/60000 ( 64%)]\tloss:0.461597\n",
      "train epoch : 8[64/60000 ( 85%)]\tloss:0.402131\n",
      "[8] test loss : 0.3731, accuracy: 86.04%\n",
      "train epoch : 9[64/60000 ( 0%)]\tloss:0.461212\n",
      "train epoch : 9[64/60000 ( 21%)]\tloss:0.322275\n",
      "train epoch : 9[64/60000 ( 43%)]\tloss:0.592907\n",
      "train epoch : 9[64/60000 ( 64%)]\tloss:0.303443\n",
      "train epoch : 9[64/60000 ( 85%)]\tloss:0.475819\n",
      "[9] test loss : 0.3680, accuracy: 86.51%\n",
      "train epoch : 10[64/60000 ( 0%)]\tloss:0.451482\n",
      "train epoch : 10[64/60000 ( 21%)]\tloss:0.410719\n",
      "train epoch : 10[64/60000 ( 43%)]\tloss:0.765662\n",
      "train epoch : 10[64/60000 ( 64%)]\tloss:0.442797\n",
      "train epoch : 10[64/60000 ( 85%)]\tloss:0.290008\n",
      "[10] test loss : 0.3738, accuracy: 86.28%\n",
      "train epoch : 11[64/60000 ( 0%)]\tloss:0.273370\n",
      "train epoch : 11[64/60000 ( 21%)]\tloss:0.480883\n",
      "train epoch : 11[64/60000 ( 43%)]\tloss:0.402805\n",
      "train epoch : 11[64/60000 ( 64%)]\tloss:0.445818\n",
      "train epoch : 11[64/60000 ( 85%)]\tloss:0.527337\n",
      "[11] test loss : 0.3500, accuracy: 87.16%\n",
      "train epoch : 12[64/60000 ( 0%)]\tloss:0.435694\n",
      "train epoch : 12[64/60000 ( 21%)]\tloss:0.409374\n",
      "train epoch : 12[64/60000 ( 43%)]\tloss:0.227835\n",
      "train epoch : 12[64/60000 ( 64%)]\tloss:0.318618\n",
      "train epoch : 12[64/60000 ( 85%)]\tloss:0.220012\n",
      "[12] test loss : 0.3476, accuracy: 87.56%\n",
      "train epoch : 13[64/60000 ( 0%)]\tloss:0.393206\n",
      "train epoch : 13[64/60000 ( 21%)]\tloss:0.417217\n",
      "train epoch : 13[64/60000 ( 43%)]\tloss:0.394123\n",
      "train epoch : 13[64/60000 ( 64%)]\tloss:0.382523\n",
      "train epoch : 13[64/60000 ( 85%)]\tloss:0.363851\n",
      "[13] test loss : 0.3350, accuracy: 87.98%\n",
      "train epoch : 14[64/60000 ( 0%)]\tloss:0.267581\n",
      "train epoch : 14[64/60000 ( 21%)]\tloss:0.463831\n",
      "train epoch : 14[64/60000 ( 43%)]\tloss:0.484220\n",
      "train epoch : 14[64/60000 ( 64%)]\tloss:0.511518\n",
      "train epoch : 14[64/60000 ( 85%)]\tloss:0.485236\n",
      "[14] test loss : 0.3298, accuracy: 88.09%\n",
      "train epoch : 15[64/60000 ( 0%)]\tloss:0.403713\n",
      "train epoch : 15[64/60000 ( 21%)]\tloss:0.232924\n",
      "train epoch : 15[64/60000 ( 43%)]\tloss:0.376313\n",
      "train epoch : 15[64/60000 ( 64%)]\tloss:0.445011\n",
      "train epoch : 15[64/60000 ( 85%)]\tloss:0.406007\n",
      "[15] test loss : 0.3266, accuracy: 88.11%\n",
      "train epoch : 16[64/60000 ( 0%)]\tloss:0.521248\n",
      "train epoch : 16[64/60000 ( 21%)]\tloss:0.335823\n",
      "train epoch : 16[64/60000 ( 43%)]\tloss:0.289073\n",
      "train epoch : 16[64/60000 ( 64%)]\tloss:0.509768\n",
      "train epoch : 16[64/60000 ( 85%)]\tloss:0.178829\n",
      "[16] test loss : 0.3285, accuracy: 88.38%\n",
      "train epoch : 17[64/60000 ( 0%)]\tloss:0.351868\n",
      "train epoch : 17[64/60000 ( 21%)]\tloss:0.448694\n",
      "train epoch : 17[64/60000 ( 43%)]\tloss:0.421779\n",
      "train epoch : 17[64/60000 ( 64%)]\tloss:0.509553\n",
      "train epoch : 17[64/60000 ( 85%)]\tloss:0.276476\n",
      "[17] test loss : 0.3205, accuracy: 88.76%\n",
      "train epoch : 18[64/60000 ( 0%)]\tloss:0.218624\n",
      "train epoch : 18[64/60000 ( 21%)]\tloss:0.383143\n",
      "train epoch : 18[64/60000 ( 43%)]\tloss:0.232672\n",
      "train epoch : 18[64/60000 ( 64%)]\tloss:0.470373\n",
      "train epoch : 18[64/60000 ( 85%)]\tloss:0.330387\n",
      "[18] test loss : 0.3201, accuracy: 88.55%\n",
      "train epoch : 19[64/60000 ( 0%)]\tloss:0.344870\n",
      "train epoch : 19[64/60000 ( 21%)]\tloss:0.298446\n",
      "train epoch : 19[64/60000 ( 43%)]\tloss:0.367778\n",
      "train epoch : 19[64/60000 ( 64%)]\tloss:0.622906\n",
      "train epoch : 19[64/60000 ( 85%)]\tloss:0.428786\n",
      "[19] test loss : 0.3069, accuracy: 88.99%\n",
      "train epoch : 20[64/60000 ( 0%)]\tloss:0.381769\n",
      "train epoch : 20[64/60000 ( 21%)]\tloss:0.292953\n",
      "train epoch : 20[64/60000 ( 43%)]\tloss:0.291990\n",
      "train epoch : 20[64/60000 ( 64%)]\tloss:0.267369\n",
      "train epoch : 20[64/60000 ( 85%)]\tloss:0.377736\n",
      "[20] test loss : 0.3098, accuracy: 88.72%\n",
      "train epoch : 21[64/60000 ( 0%)]\tloss:0.438687\n",
      "train epoch : 21[64/60000 ( 21%)]\tloss:0.273729\n",
      "train epoch : 21[64/60000 ( 43%)]\tloss:0.305836\n",
      "train epoch : 21[64/60000 ( 64%)]\tloss:0.387444\n",
      "train epoch : 21[64/60000 ( 85%)]\tloss:0.285292\n",
      "[21] test loss : 0.3068, accuracy: 89.12%\n",
      "train epoch : 22[64/60000 ( 0%)]\tloss:0.272786\n",
      "train epoch : 22[64/60000 ( 21%)]\tloss:0.290358\n",
      "train epoch : 22[64/60000 ( 43%)]\tloss:0.440066\n",
      "train epoch : 22[64/60000 ( 64%)]\tloss:0.281880\n",
      "train epoch : 22[64/60000 ( 85%)]\tloss:0.308325\n",
      "[22] test loss : 0.3050, accuracy: 89.08%\n",
      "train epoch : 23[64/60000 ( 0%)]\tloss:0.310808\n",
      "train epoch : 23[64/60000 ( 21%)]\tloss:0.351978\n",
      "train epoch : 23[64/60000 ( 43%)]\tloss:0.259424\n",
      "train epoch : 23[64/60000 ( 64%)]\tloss:0.284562\n",
      "train epoch : 23[64/60000 ( 85%)]\tloss:0.454985\n",
      "[23] test loss : 0.3145, accuracy: 88.54%\n",
      "train epoch : 24[64/60000 ( 0%)]\tloss:0.332145\n",
      "train epoch : 24[64/60000 ( 21%)]\tloss:0.426467\n",
      "train epoch : 24[64/60000 ( 43%)]\tloss:0.188809\n",
      "train epoch : 24[64/60000 ( 64%)]\tloss:0.259436\n",
      "train epoch : 24[64/60000 ( 85%)]\tloss:0.631978\n",
      "[24] test loss : 0.3022, accuracy: 89.41%\n",
      "train epoch : 25[64/60000 ( 0%)]\tloss:0.226252\n",
      "train epoch : 25[64/60000 ( 21%)]\tloss:0.450886\n",
      "train epoch : 25[64/60000 ( 43%)]\tloss:0.146871\n",
      "train epoch : 25[64/60000 ( 64%)]\tloss:0.344349\n",
      "train epoch : 25[64/60000 ( 85%)]\tloss:0.380908\n",
      "[25] test loss : 0.3015, accuracy: 88.96%\n",
      "train epoch : 26[64/60000 ( 0%)]\tloss:0.219027\n",
      "train epoch : 26[64/60000 ( 21%)]\tloss:0.161005\n",
      "train epoch : 26[64/60000 ( 43%)]\tloss:0.550730\n",
      "train epoch : 26[64/60000 ( 64%)]\tloss:0.304791\n",
      "train epoch : 26[64/60000 ( 85%)]\tloss:0.202189\n",
      "[26] test loss : 0.3025, accuracy: 89.12%\n",
      "train epoch : 27[64/60000 ( 0%)]\tloss:0.228369\n",
      "train epoch : 27[64/60000 ( 21%)]\tloss:0.279689\n",
      "train epoch : 27[64/60000 ( 43%)]\tloss:0.345228\n",
      "train epoch : 27[64/60000 ( 64%)]\tloss:0.392547\n",
      "train epoch : 27[64/60000 ( 85%)]\tloss:0.312092\n",
      "[27] test loss : 0.2988, accuracy: 89.38%\n",
      "train epoch : 28[64/60000 ( 0%)]\tloss:0.233107\n",
      "train epoch : 28[64/60000 ( 21%)]\tloss:0.245001\n",
      "train epoch : 28[64/60000 ( 43%)]\tloss:0.335505\n",
      "train epoch : 28[64/60000 ( 64%)]\tloss:0.300780\n",
      "train epoch : 28[64/60000 ( 85%)]\tloss:0.234857\n",
      "[28] test loss : 0.2986, accuracy: 89.38%\n",
      "train epoch : 29[64/60000 ( 0%)]\tloss:0.370832\n",
      "train epoch : 29[64/60000 ( 21%)]\tloss:0.202587\n",
      "train epoch : 29[64/60000 ( 43%)]\tloss:0.474455\n",
      "train epoch : 29[64/60000 ( 64%)]\tloss:0.323700\n",
      "train epoch : 29[64/60000 ( 85%)]\tloss:0.317109\n",
      "[29] test loss : 0.3012, accuracy: 89.55%\n",
      "train epoch : 30[64/60000 ( 0%)]\tloss:0.179499\n",
      "train epoch : 30[64/60000 ( 21%)]\tloss:0.326133\n",
      "train epoch : 30[64/60000 ( 43%)]\tloss:0.453755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 30[64/60000 ( 64%)]\tloss:0.333847\n",
      "train epoch : 30[64/60000 ( 85%)]\tloss:0.265803\n",
      "[30] test loss : 0.2914, accuracy: 89.36%\n",
      "train epoch : 31[64/60000 ( 0%)]\tloss:0.340110\n",
      "train epoch : 31[64/60000 ( 21%)]\tloss:0.281450\n",
      "train epoch : 31[64/60000 ( 43%)]\tloss:0.240521\n",
      "train epoch : 31[64/60000 ( 64%)]\tloss:0.268703\n",
      "train epoch : 31[64/60000 ( 85%)]\tloss:0.359744\n",
      "[31] test loss : 0.2991, accuracy: 89.56%\n",
      "train epoch : 32[64/60000 ( 0%)]\tloss:0.130420\n",
      "train epoch : 32[64/60000 ( 21%)]\tloss:0.305687\n",
      "train epoch : 32[64/60000 ( 43%)]\tloss:0.302854\n",
      "train epoch : 32[64/60000 ( 64%)]\tloss:0.431465\n",
      "train epoch : 32[64/60000 ( 85%)]\tloss:0.269225\n",
      "[32] test loss : 0.2917, accuracy: 89.59%\n",
      "train epoch : 33[64/60000 ( 0%)]\tloss:0.282261\n",
      "train epoch : 33[64/60000 ( 21%)]\tloss:0.585823\n",
      "train epoch : 33[64/60000 ( 43%)]\tloss:0.169742\n",
      "train epoch : 33[64/60000 ( 64%)]\tloss:0.309778\n",
      "train epoch : 33[64/60000 ( 85%)]\tloss:0.272854\n",
      "[33] test loss : 0.2896, accuracy: 89.67%\n",
      "train epoch : 34[64/60000 ( 0%)]\tloss:0.232265\n",
      "train epoch : 34[64/60000 ( 21%)]\tloss:0.279597\n",
      "train epoch : 34[64/60000 ( 43%)]\tloss:0.238111\n",
      "train epoch : 34[64/60000 ( 64%)]\tloss:0.431915\n",
      "train epoch : 34[64/60000 ( 85%)]\tloss:0.449411\n",
      "[34] test loss : 0.2948, accuracy: 89.54%\n",
      "train epoch : 35[64/60000 ( 0%)]\tloss:0.504256\n",
      "train epoch : 35[64/60000 ( 21%)]\tloss:0.310683\n",
      "train epoch : 35[64/60000 ( 43%)]\tloss:0.240240\n",
      "train epoch : 35[64/60000 ( 64%)]\tloss:0.184311\n",
      "train epoch : 35[64/60000 ( 85%)]\tloss:0.263505\n",
      "[35] test loss : 0.3103, accuracy: 88.81%\n",
      "train epoch : 36[64/60000 ( 0%)]\tloss:0.197171\n",
      "train epoch : 36[64/60000 ( 21%)]\tloss:0.170762\n",
      "train epoch : 36[64/60000 ( 43%)]\tloss:0.336447\n",
      "train epoch : 36[64/60000 ( 64%)]\tloss:0.278053\n",
      "train epoch : 36[64/60000 ( 85%)]\tloss:0.444289\n",
      "[36] test loss : 0.2915, accuracy: 89.62%\n",
      "train epoch : 37[64/60000 ( 0%)]\tloss:0.441019\n",
      "train epoch : 37[64/60000 ( 21%)]\tloss:0.356479\n",
      "train epoch : 37[64/60000 ( 43%)]\tloss:0.415468\n",
      "train epoch : 37[64/60000 ( 64%)]\tloss:0.216574\n",
      "train epoch : 37[64/60000 ( 85%)]\tloss:0.504575\n",
      "[37] test loss : 0.2921, accuracy: 89.62%\n",
      "train epoch : 38[64/60000 ( 0%)]\tloss:0.283130\n",
      "train epoch : 38[64/60000 ( 21%)]\tloss:0.242909\n",
      "train epoch : 38[64/60000 ( 43%)]\tloss:0.335671\n",
      "train epoch : 38[64/60000 ( 64%)]\tloss:0.321552\n",
      "train epoch : 38[64/60000 ( 85%)]\tloss:0.107043\n",
      "[38] test loss : 0.2948, accuracy: 89.75%\n",
      "train epoch : 39[64/60000 ( 0%)]\tloss:0.201104\n",
      "train epoch : 39[64/60000 ( 21%)]\tloss:0.308756\n",
      "train epoch : 39[64/60000 ( 43%)]\tloss:0.262081\n",
      "train epoch : 39[64/60000 ( 64%)]\tloss:0.369943\n",
      "train epoch : 39[64/60000 ( 85%)]\tloss:0.283010\n",
      "[39] test loss : 0.3004, accuracy: 89.80%\n",
      "train epoch : 40[64/60000 ( 0%)]\tloss:0.235704\n",
      "train epoch : 40[64/60000 ( 21%)]\tloss:0.341949\n",
      "train epoch : 40[64/60000 ( 43%)]\tloss:0.212295\n",
      "train epoch : 40[64/60000 ( 64%)]\tloss:0.276580\n",
      "train epoch : 40[64/60000 ( 85%)]\tloss:0.212260\n",
      "[40] test loss : 0.2953, accuracy: 89.78%\n"
     ]
    }
   ],
   "source": [
    "# 에폭이 끝날 때 마다 테스트셋으로 모델의 성능 측정\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss =0   # 테스트 오차 값 0으로 초기화\n",
    "    correct=0     # 예측이 맞은 수 0으로 초기화\n",
    "    with torch.no_grad() : # 평가 과정에서는 기울기를 계산하지 않아도 됨\n",
    "        for data, target in test_loader :\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            # 모든 오차 더하기\n",
    "            test_loss += F.cross_entropy(output,target, reduction = 'sum').item()  #미니배치 평균 대신 합을 받아와야 함\n",
    "            pred = output.max(1, keepdim = True)[1]  # output.max()함수는 가장 큰 값과 그 값이 있는 인덱스를 출력\n",
    "            correct +=pred.eq(target.view_as(pred)).sum().item()  #eq()함수는 값이 일치하면 1, 아니면 0을 출력 \n",
    "    test_loss /= len(test_loader.dataset)  # 모델의 전체 데이터셋에 대한 오차를 테스트셋 데이터 수로 나눠 평균 구함\n",
    "    test_accuracy = 100 * correct / len(test_loader.dataset)  # 맞힌 개수의 합을 테스트셋 데이터 수로 나누고 100을 곱해 정확도 구함\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer,epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print('[{}] test loss : {:.4f}, accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-provision",
   "metadata": {},
   "source": [
    "# ResNet으로 컬러 데이터셋에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lightweight-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬러 데이터셋은 흑백 이미지보다 복잡하므로 학습을 더 많이 해야함\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efficient-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 불러오고 전처리하는 과정은 동일\n",
    "\n",
    "# 과적합 방지하기 위해 학습용 데이터셋에 RandomCrop과 RandomHorizontalFlip 같은 노이즈 추가\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', train = True, download = True, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.RandomHorizontalFlip(),transforms.RandomCrop(32, padding =4),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5 ), (0.5, 0.5, 0.5))])), batch_size = BATCH_SIZE , shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./data', train = False, download = True, transform = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5 ), (0.5, 0.5, 0.5))])), batch_size = BATCH_SIZE , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "noticed-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual 블록을 BasicBlock이라는 새로운 모듈로 정의해서 사용\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_planes, planes, stride = 1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes,planes,kernel_size = 3, stride = stride, padding =1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(드롭아웃과 같은 효과를 냄)\n",
    "        self.conv2 = nn.Conv2d(planes,planes,kernel_size = 3, stride = 1, padding =1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()  # 여러모듈을 하나의 모듈로 묶는 역할\n",
    "        if stride !=1 or in_planes !=planes:  # '만약 채널이 증폭이 된다면' 의미\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes,planes,kernel_size = 1, stride = stride, padding =1, bias = False),\n",
    "                           nn.BatchNorm2d(planes))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out +=self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "golden-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "# 이미지를 받아 컨볼루션과 배치 정규화 층을 거친 후 여러 basicblock층을 통과하고 평균 풀링과 신경망 거쳐 예측을 출력\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding =1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        # 증폭하는 역할을 하는 모듈들은 shortcut 모듈을 따로 갖게됨\n",
    "        self.layer1 = self._make_layer(16,2, stride =1)  # 16채널에서 16채널을 내보내는 BasicBlock 2개\n",
    "        self.layer2 = self._make_layer(32,2, stride =2)  # 16채널 받아 32채널을 출력하는 BasicBlock 1개 + 32채널에서 32채널을 내보내는 BasicBlock 1개\n",
    "        self.layer3 = self._make_layer(64,2, stride =2)  # 32채널 받아 64채널을 출력하는 BasicBlock 1개 + 64채널에서 64채널을 내보내는 BasicBlock 1개\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def _make_layer(self,planes, num_blocks,stride):  # 여러 BasicBlock을 모듈 하나로 묶어주는 역할\n",
    "        strides = [stride] + [1] * (num_blocks-1)  # layer1을 예시로 보면 stride가 1이니까 [1] + [1]*1이어서 [1,1] or [1],[1]이 될 것\n",
    "        layers = []\n",
    "        for stride in strides:  # BasicBlock에서 각각 블럭이 stride 몇인지 지정하는 역할\n",
    "            layers.append(BasicBlock(self.in_planes,planes,stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)  # layers의 모든 원소를 가져오겠다는 의미\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out,8)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "everyday-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서는 학습 효율을 높이기 위해 학습률 감소 기법을 사용 -> optim.lr_scheduler.StepLR도구 사용해 간단하게 적용 가능\n",
    "\n",
    "model = ResNet().to(DEVICE)  # 만든 모델 인스턴스\n",
    "optimizer = optim. SGD(model.parameters(), lr = 0.1, momentum = 0.9, weight_decay = 0.0005) # 최적화 함수\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size = 50, gamma = 0.1)  # 50번 호출될 때 학습률에 0.01을 곱한다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "national-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "completed-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if batch_idx % 200 == 0 :\n",
    "#             print('train epoch : {}[{}/{} ({: .0f}%)]\\tloss:{:.6f}'.format(epoch, len(data), len(train_loader.dataset),\n",
    "#                                                                            100* batch_idx / len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "faced-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss =0   # 테스트 오차 값 0으로 초기화\n",
    "    correct=0     # 예측이 맞은 수 0으로 초기화\n",
    "    with torch.no_grad() : # 평가 과정에서는 기울기를 계산하지 않아도 됨\n",
    "        for data, target in test_loader :\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            # 모든 오차 더하기\n",
    "            test_loss += F.cross_entropy(output,target, reduction = 'sum').item()  #미니배치 평균 대신 합을 받아와야 함\n",
    "            pred = output.max(1, keepdim = True)[1]  # output.max()함수는 가장 큰 값과 그 값이 있는 인덱스를 출력\n",
    "            correct +=pred.eq(target.view_as(pred)).sum().item()  #eq()함수는 값이 일치하면 1, 아니면 0을 출력 \n",
    "    test_loss /= len(test_loader.dataset)  # 모델의 전체 데이터셋에 대한 오차를 테스트셋 데이터 수로 나눠 평균 구함\n",
    "    test_accuracy = 100 * correct / len(test_loader.dataset)  # 맞힌 개수의 합을 테스트셋 데이터 수로 나누고 100을 곱해 정확도 구함\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "periodic-bracelet",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (17) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-baafb122fb11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 앞과 달라진 점. scheduler.step함수로 학습률을 조금 낮춰주는 단계 추가된 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[{}] test loss : {:.4f}, accuracy: {:.2f}%'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-d969be48202a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch_3min\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-94d86fc0b7a3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch_3min\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch_3min\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch_3min\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-227a68f0982b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (17) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    scheduler.step()  # 앞과 달라진 점. scheduler.step함수로 학습률을 조금 낮춰주는 단계 추가된 것\n",
    "    train(model, train_loader, optimizer,epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print('[{}] test loss : {:.4f}, accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-phone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(practice)",
   "language": "python",
   "name": "pytorch_3min"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
