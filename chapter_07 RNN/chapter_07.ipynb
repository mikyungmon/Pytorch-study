{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greek-breach",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-adrian",
   "metadata": {},
   "source": [
    "# 7.2 영화 리뷰 감정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-arrest",
   "metadata": {},
   "source": [
    "7.2.1 자연어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구현과 학습에 필요한 라이브러리 임포트하기\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets  # 자연어 다루기 때문에 torchvision이 아니라 torchtext 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "# 모델 구현과 학습에 필요한 하이퍼파라미터 정의\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습합니다:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "differential-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩중...\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩하기\n",
    "print(\"데이터 로딩중...\")\n",
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)\n",
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n",
    "TEXT.build_vocab(trainset, min_freq=5)\n",
    "LABEL.build_vocab(trainset)\n",
    "\n",
    "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False)\n",
    "\n",
    "\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selective-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset의 구성요소 출력:  {'text': <torchtext.data.field.Field object at 0x00000220F38489A0>, 'label': <torchtext.data.field.Field object at 0x00000220F3848970>}\n",
      "testset의 구성요소 출력:  {'text': <torchtext.data.field.Field object at 0x00000220F38489A0>, 'label': <torchtext.data.field.Field object at 0x00000220F3848970>}\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터셋 로딩하고 텐서로 변환하기\n",
    "# 우선 텍스트 형태의 영화 리뷰들과 그에 해당하는 레이블을 텐서로 바꿔줄 때 필요한 설정을 정함\n",
    "# 즉, torchtext.data의 Field 클래스를 사용하여 영화 리뷰에 대한 객체 TEXT, 레이블을 위한 객체 LABEL을 생성한다는 것\n",
    "\n",
    "# sequential은 순차적인 데이터 셋인지를 명시하는 역할\n",
    "# batch_first는 신경망에 입력되는 텐서의 첫 번째 차원값이 batch_size가 되도록 정해주는 역할\n",
    "# lower은 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 처리하는 역할\n",
    "TEXT = data.Field(sequential = True, batch_first = True, lower = True)  \n",
    "LABEL = data.Field(sequential = False, batch_first = True)\n",
    "\n",
    "# 그 다음으로는 datasets의 객체의 splits 함수를 이용해 모델에 입력되는 데이터셋을 만들어줌\n",
    "# (IMDB 리뷰 데이터를 다운 받는 동시에 훈련 데이터와 테스트 데이터를 분할하고, 각각 trainset, testset에 저장)\n",
    "trainset, testset = datasets.IMDB.splits(TEXT,LABEL)\n",
    "\n",
    "# 리뷰 데이터가 저장되어 있는 text필드와 레이블이 저장되어 있는 label 필드가 존재\n",
    "print ('trainset의 구성요소 출력: ', trainset.fields)\n",
    "print ('testset의 구성요소 출력: ', testset.fields)\n",
    "\n",
    "# 만들어진 데이터셋을 이용해 워드 임베딩에 필요한 단어 사전 만들기\n",
    "# 사전이란 중복을 제거한 총 단어들의 집합 의미\n",
    "TEXT.build_vocab(trainset, min_freq = 5)  # min_freq은 학습 데이터에서 최소 5번 이상 등장한 단어만 사전에 담겠다는 의미, 5번 이하는 unk토큰으로 대체됨\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concrete-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터셋에선 따로 검증셋이 존재하지 않기 때문에 학습셋을 쪼개서 사용함\n",
    "trainset,valset = trainset.split(split_ratio=0.8)   # 학습셋이 80%, 검증셋이 20%가 되도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 형태의 데이터도 모든 학습 데이터를 한번에 처리하기보단 batch단위로 쪼개서 학습을 진행해야함\n",
    "# trainset, valset, testset에서 반복할 때마다 배치를 생성해주는 반복자 만듦\n",
    "# 이 반복자를 enumerate함수에 입력시켜 루프를 구현하면 루프 때마다 전체 데이터셋에서 배치 단위의 데이터가 생성됨    ?????무슨소리\n",
    "# 토치 텍스트는 단어를 인덱스 번호로 대체하는 BucketIterator를 제공함\n",
    "# 이제 train_iter, val_iter, test_iter에는 샘플과 레이블이 64개 단위 묶음으로 저장됨\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((trainset,valset,testset), batch_size = BATCH_SIZE, shuffle = True,\n",
    "                                                            repeat = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "convertible-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 57\n",
      "테스트 데이터의 미니 배치의 개수 : 391\n",
      "검증 데이터의 미니 배치의 개수 : 15\n"
     ]
    }
   ],
   "source": [
    "# 64개씩 묶었을 때 총 배치의 개수가 몇 개가 되는지 출력\n",
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elect-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 속 단어들의 개수와 레이블 수를 정해주는 변수 생성\n",
    "vocab_size = len(TEXT.vocab)   # 중복을 제거한 총 단어의 갯수 의미\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "worthy-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[학습셋]: 3647 [검증셋]: 912 [테스트셋]: 25000 [단어수]: 13402 [클래스] 2\n"
     ]
    }
   ],
   "source": [
    "# 학습셋, 검증셋, 테스트셋의 예제 갯수 출력\n",
    "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\" % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-narrow",
   "metadata": {},
   "source": [
    "7.2.2 RNN 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "going-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p = 0.2):\n",
    "        super(BasicGRU,self).__init__()\n",
    "        print(\"Building Basic GRU Model...\")\n",
    "        self.n_layers = n_layers  # n_layers는 은닉 벡터들의 층( 아주 복잡한 모델 아닌 이상 2로 정의하는게 보통 )\n",
    "        \n",
    "         # n_vocab은 전체 데이터셋의 모든 단어를 사전 형태로 나타냈을 때 그 사전에 등재된 단어 수\n",
    "        # embed_dim은 임베딩된 단어 텐서가 지니는 차원 값\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim) \n",
    "        \n",
    "        # RNN통해 생성되는 은닉 벡터의 차원값과 드롭아웃을 정의\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # RNN 모델 정의\n",
    "        # RNN은 입력이 길어지면 학습 도중 기울기가 너무 작아지거나 커져서 앞부분에 대한 정보를 담지 못할 수도 있음\n",
    "        # 따라서 이러한 결함을 보완한 GRU 사용\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
    "        \n",
    "        # GRU도 시계열 데이터 하나를 하나의 텐서로 압축 -> 문장 전체에 대한 맥락 담고 있음\n",
    "        # 영화 리뷰가 긍정인지 부정인지 분류하기 위해서 압축된 텐서를 신경망에 통과시켜 클래스에 대한 예측을 출력하도록 함\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        # 첫 번째 은닉 벡터\n",
    "        h_0 = self._init_state(batch_size = x.size(0))  # 모든 특성값이 0인 벡터로 설정됨\n",
    "        \n",
    "        # x를 첫 번째 은닉 벡터 h_0과 함께 self.gru함수에 입력하면 은닉 벡터들이 시계열 배열 형태로 반환됨\n",
    "        # 즉, self.gru(x,h_o)의 결과값은 (batch_size, 입력 x의 길이, hidden_dim)의 모양을 지닌 3차원 텐서\n",
    "        x, _ = self.gru(x,h_0)  \n",
    "        \n",
    "        # 배치 내 모든 시계열 은닉 벡터들의 마지막 토큰들을 내포한 (batch_size,1,hidden_dim)모양의 텐서를 추출할 수 있음\n",
    "        h_t = x[:,-1,:]  # 영화 리뷰 배열들을 압축한 은닉 벡터\n",
    "        self.dropout(h_t)\n",
    "        \n",
    "        logit = self.out(h_t)\n",
    "        return logit\n",
    "        \n",
    "    def _init_state(self,batch_size = 1):\n",
    "        # parameters함수는 그 신경망 모듈의 가중치 정보를 반복자 형태로 반환\n",
    "        # 이 반복자가 생성하는 원소들은 각각 실제 신경망의 가중치 텐서를 지닌 객체들\n",
    "        weight = next(self.parameters()).data  # nn.GRU모듈의 첫 번째 가중치 텐서를 추출\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "packed-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(학습) 함수와 evaluate(평가) 함수 구현\n",
    "\n",
    "# train\n",
    "def train(model,optimizer,train_iter):\n",
    "    model.train()\n",
    "    for b,batch in enumerate(train_iter):  # 반복마다 배치 데이터 반환, 배치 내의 영화평 데이터와 그에 상응하는 레이블에 접근\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub(1)  # batch.label은 1이나 2의 값을 가지고 있어서 1씩 빼서 0 또는 1 값으로 만들어줌\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(x)   # 예측값\n",
    "        loss = F.cross_entropy(logit,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "# evaluate - 검증셋과 테스트셋의 성능 측정을 위한 함수\n",
    "# 경사하강 과정을 건너뛰는 것을 빼고는 train함수와 거의 같음. but, 모델의 평가를 위해 데이터셋에 대한 loss값과 정확도의 평균을 반환함\n",
    "def evaluate(model,val_iter):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0,0\n",
    "    for batch in val_iter :\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE) \n",
    "        y.data.sub(1)  # batch.label은 1이나 2의 값을 가지고 있어서 1씩 빼서 0 또는 1 값으로 만들어줌\n",
    "        logit = model(x)   # 예측값\n",
    "        # loss값과 정확도를 구하기 위해 각 배치의 평균을 구하는게 아니라 데이터셋 전체의 합을 구함\n",
    "        loss = F.cross_entropy(logit,y,reduction = 'sum')  # 오차의 합 구함\n",
    "        total_loss +=loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum() # 모델의 맞힌 수\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "common-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU Model...\n"
     ]
    }
   ],
   "source": [
    "# 모델 객체 정의\n",
    "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE) # 모델 내 은닉 벡터의 차원값 : 256, 임베딩된 토큰의 차원값 : 128 으로 임의로 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southwest-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이폭: 1] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 2] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 3] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 4] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 5] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 6] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 7] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 8] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 9] 검증 오차: 0.00 | 검증 정확도:100.00\n",
      "[이폭: 10] 검증 오차: 0.00 | 검증 정확도:100.00\n"
     ]
    }
   ],
   "source": [
    "# 학습 실행\n",
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # 최종 모델은 학습 오차가 아닌 검증 오차가 최소화된 모델을 원함\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:  # best_val_loss가 아니거나 val_loss가 best_val_loss보다 작으면 수행\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "manufactured-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차:  4.75  |  테스트 정확도: 50.00\n"
     ]
    }
   ],
   "source": [
    "# 학습 마친 후 테스트 셋으로 모델의 성능을 시험\n",
    "# 검증셋에서 가장 성능이 좋았던 모델을 불러와 테스트\n",
    "\n",
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
    "test_loss, test_accuracy = evaluate(model,test_iter)\n",
    "print('테스트 오차: %5.2f  |  테스트 정확도: %5.2f' % (test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-rental",
   "metadata": {},
   "source": [
    "# 7.3 Seq2Seq 기계 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-consequence",
   "metadata": {},
   "source": [
    "7.3.4 Seq2Seq 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hundred-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 필요한 라이브러리 임포트\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "requested-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 속에 총 몇 종류의 토큰이 있는지 정의\n",
    "# 영문만 다룰 것이므로 영문을 숫자로 표현하는 방식인 아스키 코드로 임베딩을 대신할 것임\n",
    "# 아스키 코드로는 총 256개의 글자를 표현할 수 있으므로 사전에 담을 수 있는 토큰의 수를 256으로 정의\n",
    "vocab_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "australian-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "# 모델에 입력될 원문과 번역문을 아스키 코드의 배열로 정의하고 파이토치 텐서로 바꾸기\n",
    "\n",
    "x_ = list(map(ord,\"hello\"))  # ord는 문자의 아스키 값을 돌려주는 함수\n",
    "y_ = list(map(ord,\"hola\"))   # map은 함수와 반복 가능한 자료형을 입력받아서 그 자료형의 각 요소를 함수를 수행한 결과를 묶어서 돌려주는 함수\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)\n",
    "x = torch.LongTensor(x_)     # 파이토치 텐서로 바꾸기\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "spread-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        # 원문과 번역문의 문자체계가 완전히 다르면 임베딩을 따로 만들어야하지만 이번 예제에서는 둘 다 아스키코드로 나타내서 하나만 만들어도됨\n",
    "        self.embedding = nn.Embedding(vocab_size,hidden_size)   # hidden_size는 임베딩된 토큰의 차원값을 말함\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
    "        # 디코더가 번역문의 다음 토큰을 예상해내는 작은 신경망을 하나 더 만들어줌\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)  # 왜 만드는건지 이해 못함\n",
    "        \n",
    "    def forward(self,inputs,targets):\n",
    "        initial_state = self._init_state()  # 인코더의 첫 번째 은닉 벡터를 정의   (첫 번째 은닉 벡터가 뭔지 모르겠음)\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)  # 인코더에 입력되는 원문을 구성하는 모든 문자(\"hello\")를 임베딩시킴\n",
    "        \n",
    "        # 원문을 인코더에 입력해서 문맥 벡터인 encoder_state를 만듦\n",
    "        # 디코더가 번역문의 첫 번째 토큰을 예상하려면 인코더의 문맥 벡터와 문장 시작 토큰을 입력 데이터로 받아야함\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)  # output은 무엇?\n",
    "        decoder_state = encoder_state  # 문맥 벡터를 디코더의 첫 번째 은닉 벡터 decoder_state로 지정함\n",
    "        \n",
    "        # 문장 시작 토큰은 실제로 문장에 나타나지는 않지만 디코더가 정상적으로 작동할 수 있게 넣은 토큰\n",
    "        # 디코더에 문장의 시작을 알리기 위함이며 아스키 값으로 공백 문자를 뜻하는 0으로 설정함\n",
    "        decoder_input = torch.LongTensor([0])   # 문장 시작 토큰\n",
    "        \n",
    "        outputs = []\n",
    "        # 디코더는 문장 시작 토큰인 아스키 번호 0을 이용해 번역문 hola의 h 토큰을 예측했으면 다음 반복에서는 h토큰 이용해 o토큰 예측해야함\n",
    "        for i in range(targets.size()[0]):\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            \n",
    "            # 디코더 결과값은 다시 디코더 모델에 입력됨\n",
    "            # 디코더 출력값이 신경망의 마지막 층인 소프트맥스 층을 거치면 번역문의 다음 예상 글자가 나옴\n",
    "            projection = self.project(decoder_output)\n",
    "            outputs.append(projection)   # 이 예상 결과를 outputs텐서에 저장해 오차를 계산할 때 사용할 것임\n",
    "            \n",
    "            # 디코더 학습 시 실제 번역문의 토큰을 디코더의 전 출력값 대신 입력으로 사용해 학습을 가속하는 방법\n",
    "            decoder_input = torch.LongTensor([targets[i]])  # 티처 포싱\n",
    "           \n",
    "        outputs = torch.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "        \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "attended-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "criterion = nn.CrossEntropyLoss()    # 교차 크로스 엔트로피 오차 함수\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(),lr=1e-3)   # 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "normal-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 반복:0 오차: 5.758358001708984\n",
      "['X', 'X', 'Î', 'Ø']\n",
      "\n",
      " 반복:100 오차: 2.191209316253662\n",
      "['o', 'o', 'a', 'a']\n",
      "\n",
      " 반복:200 오차: 0.7097018957138062\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:300 오차: 0.355837881565094\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차: 0.23188045620918274\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차: 0.16872064769268036\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차: 0.13022974133491516\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차: 0.10436157882213593\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차: 0.08586667478084564\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차: 0.07206021249294281\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(1000):  # 1000번의 이폭을 거쳐 모델 학습\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "critical-faculty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습을 진행하면서 오차가 줄어드는 것을 시각화\n",
    "\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-lawyer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(practice)",
   "language": "python",
   "name": "pytorch_3min"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
